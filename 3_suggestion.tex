%%%%%%%%%%%% ------------ chapter header ------------  %%%%%%%%%%%%
\chapterhead
% chapter title
{提案手法}
% chapter abst
{本章では，提案手法について説明する．}

%信号の全体像（白畑さん，伊藤先生）の部分も書いく
%ハンガリアンアルゴリズム
%フローを記入

%%%%%%%%%%%% ------------ next page ------------  %%%%%%%%%%%%
\section{概要}
本研究の目的は1章でも述べたように，リアルタイムで車両の状態を推定することである．%自立分散型信号機に必要な要件が必要
図 のように各信号機に対応する車道を撮る監視カメラを用いて，各監視カメラ映像に画像処理を行う．%kai（図解）
さらに，実空間上での検証を行うためにもセンサの堅牢性やコスト等を考える必要があるたり，
本研究ではソフトウェアとハードウェアの2つの側面からシステムの構築を考える．
ソフトウェアではYOLOv4とDeepSORTを用いたオブジェクトマルチトラックングおよび，車種特定を行う．
ハードウェアは監視カメラとしてPanasonic製のネットワークカメラ\cite{wv_s1531lnj}と，
エッジセンサとしてNVIDIA製のJetson Xavier NX\cite{jetson}，信号制御装置としてRaspberry Pi 4\cite{raspi}の4GBモデルを採用した．
これらの装置を各信号機に１セットずつ配置し，それぞれのセットを同一のWi-Fiネットワークで繋ぎ同期するようにした．

\begin{figure}[h]
    \includegraphics*[bb=0 0 950 700, width=1\linewidth]{./images/networkcamera.jpg}
    \caption{ネットワークカメラ WV-S1531LNJ} 
    \label{tab:networkcamera}
  \end{figure}

\begin{figure}[t]
    \includegraphics*[bb=0 0 950 700, width=1\linewidth]{./images/jetsonNX.png}
    \caption{Jetson Xavier NX} 
    \label{tab:jetson}
  \end{figure}

  \begin{figure}[t]
    \includegraphics*[bb=0 0 950 600, width=1\linewidth]{./images/raspi4.png}
    \caption{Raspberry Pi 4} 
    \label{tab:raspi}
  \end{figure}


\section{センサの要件}
本研究の要件は大まかにソフトウェアとハードウェアの2つの側面に分けることができる．
\subsection{ソフトウェアの要件}
\begin{enumerate}
	\item 車両の位置情報推定
	\item (車種推定
	\item (交差点内の右左折待ち状態の推定
	\item (複数のカメラ間での同一車両のマッチング
	\item (オクルージョンの改善
\end{enumerate}

1は，2章関連研究でも述べたようにDeepSORTを用いることで解決できる．さらに，既存研究を参考に射影変換を用いることでマップへの車両位置の投影を行った．

\subsection{ハードウェアの要件}
\begin{enumerate}
	\item 信号機の設置されている交差点からおよそ150mまでの状態を知ることができる．%kai（時速との兼ね合い）
	\item 実空間での設置を想定した堅牢性があること．
	\item 設置コストを抑えること．
\end{enumerate}
1はSUMOを扱う際に，信号機の動的制御までに十分な時間を確保するために，交差点から150m先の各車両の状態を知る必要がある．
2は信号機の特性上，トラブルは最小限に抑えるべきであり，システムが何らかの原因で止まったしまった場合でも，信号機としての役割を果たせるようにする必要がある．
3は全国的に普及させるためにも，あらゆるコストを抑え小規模でかつシンプルなものにするべきだと考えられる．


実空間上で設置するセンサとしての要件を満たしつつ，さらに既存研究のモデルに当てはめるだけの性能を持つセンサの開発が必要である．

\subsection{車両の位置推定}
車両の位置を推定する際に監視カメラから得られた動画内にある車両をオブジェクトとして認識する必要がある．
そこで，YOLOv4\cite{bochkovskiy2020yolov4}を用いて車両を認識する．
ただし，オブジェクトは次フレームでは別のオブジェクトとして認識されてしまうので，
カルマンフィルタを用いて前フレームで認識したオブジェクトを次フレームでも認識できるようにする．
これにより，オブジェクトがBBOXが画像のXY座標で表すことができるよになる．
車両大きさ，カメラからの距離によってによってBBOXのサイズ一定でないことから，射影変化する際は，BBOXの下辺の中点を座標として定義した．
この座標を射影変換し，実際の地図に対応させる．射影変換の式は以下のように求める．
\begin{equation}
    p = [x, y, 1]^T, P = [X, Y, 1]^T
  \end{equation}
  \begin{equation}
    P' = [X', Y', W']^T = Hp
  \end{equation}
  \begin{equation}
    P = \frac{1}{W'}P'
\end{equation}
ここで，$p$はカメラ画像の座標，$P$は地図上の座標を表ている．$(x,y)$は画像の左上を原点$o = (0, 0)$として正の値を取る座標であり，
$H$はホモグラフィ行列を表す．
射影変換は道路の角を4点決め，地図でもそれに対応した4点を決める．
この点同士からホモグラフィ行列を求めることで，カメラ画像内のオブジェクトの座標がリアルタイムで地図上に反映される．
%kai（4点決めの画像）

\subsection{車両の速度}
車両の位置推定を行った後，地図上で速度を計測する，

\section{Re-id}
4台のカメラで捉えた同一車両のマッチングを行う．
1台のカメラから捉えた車両の特徴は全てのエッジセンサに共有される．
共有される特徴は，ID，車種，移動軌跡となる．


\subsection{車両の種類}
車両の種類の特定は，YOLOv4の◯◯を用いた．
  
\subsection{交差点内の右左折待ち}
交差点内の右左折待ちは，時間と車両の位置，ウィンカーの有無で判定を行う．


\subsection{オクルージョンの解決}
車両が前方の車両に隠れて見えなくなってしまことがある．このオクルージョンを解決するために
道路の範囲を指定し，オクルージョンが発生する前に認識した車両は前方の車に隠れていると判定するようにした．

\newpage
